{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 1048576\n",
      "Test data size: 360\n",
      "Data shape: (1048576, 2)\n",
      "Sentiment distribution:\n",
      " 0            800000\n",
      "1            248575\n",
      "Sentiment         1\n",
      "Name: Sentiment, dtype: int64\n",
      "Number of missing values:\n",
      " Sentiment    0\n",
      "Text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('train.csv', names=['Sentiment', 'Text'], dtype={'Sentiment': str, 'Text': str}, low_memory=False)\n",
    "train_df.dropna(inplace=True)\n",
    "\n",
    "test_df = pd.read_csv('test.csv', names=['Sentiment', 'Text'], dtype={'Sentiment': str, 'Text': str})\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "print('Train data size:', len(train_df))\n",
    "print('Test data size:', len(test_df))\n",
    "\n",
    "# Step 1: Exploratory Data Analysis\n",
    "print(\"Data shape:\", train_df.shape)\n",
    "print(\"Sentiment distribution:\\n\", train_df['Sentiment'].value_counts())\n",
    "print(\"Number of missing values:\\n\", train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Text Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove digits and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    return text\n",
    "\n",
    "train_df['Text'] = train_df['Text'].apply(preprocess_text)\n",
    "test_df['Text'] = test_df['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 3: Linguistic Feature Extraction\n",
    "# Bag-of-words features\n",
    "vectorizer_bow = CountVectorizer()\n",
    "bow_features = vectorizer_bow.fit_transform(train_df['Text'])\n",
    "\n",
    "# TF-IDF features\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "tfidf_features = vectorizer_tfidf.fit_transform(train_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Step 4: Build your sentiment classification model\n",
    "# Split the data into training and testing sets\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(bow_features[:len(train_df)], train_df['Sentiment'], test_size=0.2, random_state=42)\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tfidf_features[:len(train_df)], train_df['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression model with Bag-of-words features\n",
    "lr_bow = LogisticRegression(max_iter=100000)\n",
    "lr_bow.fit(X_train_bow, y_train_bow)\n",
    "y_pred_bow_lr = lr_bow.predict(X_test_bow)\n",
    "\n",
    "# Logistic Regression model with TF-IDF features\n",
    "lr_tfidf = LogisticRegression(max_iter=100000)\n",
    "lr_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_tfidf_lr = lr_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Naive Bayes model with Bag-of-words features\n",
    "nb_bow = MultinomialNB()\n",
    "nb_bow.fit(X_train_bow, y_train_bow)\n",
    "y_pred_bow_nb = nb_bow.predict(X_test_bow)\n",
    "\n",
    "# Naive Bayes model with TF-IDF features\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_tfidf_nb = nb_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Bag-of-words features\n",
      "Accuracy: 0.8493772530469779\n",
      "Precision: 0.8416011100852809\n",
      "Recall: 0.8493772530469779\n",
      "F1 score: 0.8407265186999815\n",
      "Logistic Regression with TF-IDF features\n",
      "Accuracy: 0.8529535180911327\n",
      "Precision: 0.8458368485295767\n",
      "Recall: 0.8529535180911327\n",
      "F1 score: 0.8435115325701856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Step 5: Model evaluation\n",
    "# Evaluate the models using accuracy, precision, recall, and F1 score\n",
    "print(\"Logistic Regression with Bag-of-words features\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_bow, y_pred_bow_lr))\n",
    "print(\"Precision:\", precision_score(y_test_bow, y_pred_bow_lr, average='weighted',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test_bow, y_pred_bow_lr, average='weighted'))\n",
    "print(\"F1 score:\", f1_score(y_test_bow, y_pred_bow_lr, average='weighted'))\n",
    "\n",
    "print(\"Logistic Regression with TF-IDF features\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_tfidf, y_pred_tfidf_lr))\n",
    "print(\"Precision:\", precision_score(y_test_tfidf, y_pred_tfidf_lr, average='weighted',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test_tfidf, y_pred_tfidf_lr, average='weighted'))\n",
    "print(\"F1 score:\", f1_score(y_test_tfidf, y_pred_tfidf_lr, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e30c83b22147918c25b1d9fc834badab54b575e3debac97aebc070033583df6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
